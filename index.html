<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="description" content="Wenqi Wang's personal homepage. Research projects, publications, and contact information.">
    <meta name="keywords" content="Wenqi Wang, Computer Science, Boston University, Vision-Language Models, Computer Vision, Research">
    <title>Wenqi Wang</title>
    <link rel="canonical" href="https://wqwang.me">

    <meta name="author" content="Wenqi Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Wenqi Wang (王文琦)
                </p>
                Hello! I am a Ph.D. student in Computer Science at Boston University, where I am fortunate to be advised by <a href="http://boqinggong.info/">Prof. Boqing Gong</a>.
                </p>
                <p>
                  I completed my Bachelor's degree in Computer Science and Technology at Tsinghua University. My research focuses on computer vision, with a particular interest in vision-language foundation models and their
                  applications in understanding and generating multimodal content.
                </p>
                <p style="text-align:center">
                  <a href="mailto:wqwang@bu.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/Wenqi_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=spG4edsAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/vextawang">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/wenqi-wang20">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/profile/wenqi.jpg"><img style="width:100%;max-width:100%;object-fit: cover;border-radius: 50%" alt="profile photo" src="images/profile/wenqi.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <!-- <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>.
                </p> -->
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;text-align:center">
        <img src='images/papers/site_bench/site_bench.png' style="width:100%;max-width:100%;height:auto;">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://wenqi-wang20.github.io/SITE-Bench.github.io/">
          <span class="papertitle">SITE: towards Spatial Intelligence Thorough Evaluation</span>
        </a>
        <br>
        <strong>Wenqi Wang</strong>,
        <a href="https://rxtan2.github.io/">Reuben Tan</a>,
        <a href="https://scholar.google.com/citations?user=BJXBjY4AAAAJ">Pengyue Zhu</a>,
        <a href="https://jwyang.github.io/">Jianwei Yang</a>,
        <a href="https://zyang-ur.github.io/">Zhengyuan Yang</a>,
        <a href="https://www.microsoft.com/en-us/research/people/lijuanw/">Lijuan Wang</a>,
        <a href="https://www.microsoft.com/en-us/research/people/akolobov/">Andrey Kolobov</a>,
        <a href="https://www.microsoft.com/en-us/research/people/jfgao/">Jianfeng Gao</a>,
        <a href="http://boqinggong.info/">Boqing Gong</a>
        <br>
        <em>ICCV</em>, 2025
        <br>
        <a href="https://wenqi-wang20.github.io/SITE-Bench.github.io/">project page</a>
        /
        <a href="https://github.com/wenqi-wang20/SITE-Bench">code</a>
        /
        <a href="https://arxiv.org/abs/2505.05456">arXiv</a>
        <p></p>
        <p>
        We curate a benchmark combining a bottom-up survey and a top-down strategy drawing upon three classification systems
        in cognitive science, including 31 computer vision datasets and 8000+ evaluation samples.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:40%;vertical-align:middle;text-align:center">
        <img src='images/papers/slice3d/slice3d.png' style="width:100%;max-width:100%;height:auto;">
      </td>
      <td style="padding:20px;width:60%;vertical-align:middle">
        <a href="https://yizhiwang96.github.io/Slice3D/">
          <span class="papertitle">Slice3D: Multi-Slice, Occlusion-Revealing, Single View 3D Reconstruction</span>
        </a>
        <br>
        <a href="https://yizhiwang96.github.io/">Yizhi Wang</a>,
        <a href="https://www.sfu.ca/~wpintoli/">Wallace Lira</a>,
        <strong>Wenqi Wang</strong>,
        <a href="https://www.sfu.ca/~amahdavi">Ali Mahdavi-Amiri</a>,
        <a href="https://www.cs.sfu.ca/~haoz/">Hao (Richard) Zhang</a>,
        <br>
        <em>CVPR</em>, 2024
        <br>
        <a href="https://yizhiwang96.github.io/Slice3D/">project page</a> /
        <a href="https://arxiv.org/abs/2312.02221">arXiv</a> /
        <a href="https://github.com/yizhiwang96/Slice3D">code</a> /
        <a href="https://www.youtube.com/watch?v=4MDAiFWdXRw&t=10s&ab_channel=YizhiWang">video</a>
        <p></p>
        <p>Our single-view 3D reconstruction method, Slice3D, predicts multi-slice images to reveal occluded parts without
          changing the camera (in contrast to multi-view synthesis), and then lifts the slices into a 3D model.</p>
      </td>
    </tr>


    <!-- <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()" bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat3d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat3d_start() {
            document.getElementById('cat3d_image').style.opacity = "1";
          }

          function cat3d_stop() {
            document.getElementById('cat3d_image').style.opacity = "0";
          }
          cat3d_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://cat3d.github.io/">
			<span class="papertitle">CAT3D: Create Anything in 3D with Multi-View Diffusion Models
</span>
        </a>
        <br>
				<a href="https://ruiqigao.github.io/">Ruiqi Gao</a>*,
        <a href="https://holynski.org/">Aleksander Holynski</a>*, 
        <a href="https://henzler.github.io/">Philipp Henzler</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>, 
				<a href="http://ricardomartinbrualla.com/">Ricardo Martin Brualla</a>, 
        <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>,
				<strong>Jonathan T. Barron</strong>,
        <a href="https://poolio.github.io/">Ben Poole</a>*

        <br>
        <em>arXiv</em>, 2024
        <br>
        <a href="https://cat3d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2405.10314">arXiv</a>
        <p></p>
        <p>
				A single model built around diffusion and NeRF that does text-to-3D, image-to-3D, and few-view reconstruction, trains in 1 minute, and renders at 60FPS in a browser.
        </p>
      </td>
    </tr> -->



          
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
      <tr>
        <td>
          <h2>Miscellanea</h2>
        </td>
      </tr>
    </tbody></table>
    <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
    <tr>
      <td width="100%" valign="center">
        <ul>
          <li>I enjoy photography in my spare time. Check out my <a href="gallery.html">gallery</a>!</li>
          <li>I have served as reviewer for various conferences and journals including CVPR, ICCV.</li>
        </ul>
      </td>
    </tr>
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Clone from <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
